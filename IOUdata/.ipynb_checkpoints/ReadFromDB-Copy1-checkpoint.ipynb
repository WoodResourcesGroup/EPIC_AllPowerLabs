{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is intended to show how to use pandas, and sql alchemy to upload data into DB2-switch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install using pip or any other package manager pandas, sqlalchemy and pg8000. The later one is the driver to connect to the db. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the required packages, first create the engine to connect to the DB. The approach I generally use is to create a string based on the username and password. The code is a function, you just need to fill in with the username, password and the dbname. \n",
    "\n",
    "It allows you to create different engines to connect to serveral dbs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def connection(user,passwd,dbname, echo_i=False):\n",
    "    str1 = ('postgresql+pg8000://' + user +':' + passw + '@switch-db2.erg.berkeley.edu:5432/' \n",
    "            + dbname + '?ssl=true&sslfactory=org.postgresql.ssl.NonValidatingFactory')\n",
    "    engine = create_engine(str1,echo=echo_i)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user = 'jdlara'\n",
    "passw = 'Amadeus-2010'\n",
    "dbname = 'apl_cec' \n",
    "engine= connection(user,passw,dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, use pandas to import the data from Excel files or any other text file format. Make sure that the data in good shape before trying to push it into the server. In this example I use previous knowledge of the structure of the tabs in the excel file to recursively upload each tab and match the name of the table with the tab name. \n",
    "\n",
    "Before doing this I already checked that the data is properly organized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excel_file = 'PGEFeedersFinal.xlsx'\n",
    "tab_name = ['substation_banks','substations','feeders_limits_data','feeder_minimpacts']\n",
    "schema_for_upload = 'PGE'\n",
    "for name in tab_name:\n",
    "    pd_data = pd.read_excel(excel_file, sheetname=name, encoding='UTF-8')\n",
    "    pd_data.to_sql(name, engine, schema=schema_for_upload, if_exists='replace',chunksize=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once the data is updated, it is possible to run the SQL commands to properly create ```geom``` columns in the tables, this can be done as follows. The ojective is to run an SQL querie like this: \n",
    "\n",
    "```\n",
    "set search_path = SCHEMA, public;\n",
    "alter table TABLE drop column if exists geom;\n",
    "SELECT AddGeometryColumn ('SCHEMA','TABLE','geom',4326,'POINT',2);\n",
    "UPDATE TABLE set geom = ST_SetSRID(st_makepoint(TABLE.lon, TABLE.lat), 4326)::geometry;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_geom(table,schema,engine):\n",
    "    k = engine.connect()\n",
    "    query = ('set search_path = \"'+ schema +'\"'+ ', public;')\n",
    "    print query\n",
    "    k.execute(query)\n",
    "    query = ('alter table ' + table + ' drop column if exists geom;')\n",
    "    print query\n",
    "    k.execute(query)\n",
    "    query = 'SELECT AddGeometryColumn (\\''+ schema + '\\',\\''+ table + '\\',\\'geom\\''+',4326,\\'POINT\\',2);'\n",
    "    print query\n",
    "    k.execute(query)\n",
    "    query = ('UPDATE ' + table + ' set geom = ST_SetSRID(st_makepoint(' + table + '.lon, ' + \n",
    "             table + '.lat), 4326)::geometry;')\n",
    "    k.execute(query)\n",
    "    print query\n",
    "    return 'geom column added with SRID 4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set search_path = \"PGE\", public;\n",
      "alter table feeders drop column if exists geom;\n",
      "SELECT AddGeometryColumn ('PGE','feeders','geom',4326,'POINT',2);\n",
      "UPDATE feeders set geom = ST_SetSRID(st_makepoint(feeders.lon, feeders.lat), 4326)::geometry;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'geom column added with SRID 4326'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = 'feeders'\n",
    "schema = 'PGE'\n",
    "create_geom(table,schema,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function created the geom column, the next step is to define a function to create the Primary-Key in the db. Remember that the index from the data frame is included as an index in the db, sometimes an index is not really neded and might need to be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alter table feeders ADD CONSTRAINT feeders_pk PRIMARY KEY (feeder_no)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x10ef34050>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'feeder_no'\n",
    "k = engine.connect()\n",
    "query = ('set search_path = \"'+ schema +'\"'+ ', public;')\n",
    "k.execute(query)\n",
    "query = ('alter table ' + table + ' ADD CONSTRAINT '+ table +'_pk PRIMARY KEY (' + col + ')')\n",
    "print query \n",
    "k.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALTER TABLE table_name\n",
    "  ADD CONSTRAINT [ constraint_name ]\n",
    "    PRIMARY KEY (index_col1, index_col2, ... index_col_n)"
   ]
  }
 ],
 "metadata": {
  "CodeCell": {
   "cm_config": {
    "lineWrapping": true
   }
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
